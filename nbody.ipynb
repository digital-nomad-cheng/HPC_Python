{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5176bade",
   "metadata": {},
   "source": [
    "# A simplified n-body simulation in Python\n",
    "\n",
    "For this tutorial, we will use the **gravitational N-body problem** in Python. We assume a 3D space of particles that interact with each other gravitationally and we will compute the system's kinetic and potential energy.  \n",
    "\n",
    "We assume that each particle $ i $ has a mass $ m_i $, a position $ r_i=[x,y,z] $, and a velocity $ v_i = [vx_i,vy_i,vz_i] $. According to Newton's law, each particle will experience an acceleration $ a_i = G \\sum_{j \\neq i} m_j \\frac{r_j - r_i}{|r_j - r_i|^3} $, where $ G $ is Newton's gravitational constant. \n",
    "\n",
    "We also assume that the system evolves in timesteps $\\Delta t$, in a \"kick-drift-kick\" way. First, each particle receives a half-step kick and its velocity gets updated: $ v_i = v_i + \\frac{\\Delta t}{2} \\times a_i$. Then, it updates its position using the updated velocity, $r_i = r_i + \\Delta t \\times v_i$. Finally the velocity gets updated again in the second half-step kick.\n",
    "\n",
    "The total energy of the system is $E = KE + PE = \\sum_i \\frac{1}{2}m_i{v_i}^2 - \\sum_{1\\leq i\\leq j\\leq N} \\frac{Gm_im_j}{|r_j - r_i|}$. \n",
    "\n",
    "For simplicity, we will focus on the kinetic energy (KE) only, therefore once the velocity is updated, we can compute the kinetic energy $ KE = \\sum_i \\frac{1}{2}m_i{v_i}^2 $.\n",
    "\n",
    "*Note: The code for this tutorial has been adapted from https://github.com/pmocz/nbody-python, and a description of the assumptions for the relevant implementation can be found here: https://medium.com/swlh/create-your-own-n-body-simulation-with-matlab-22344954228e*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b393670c",
   "metadata": {},
   "source": [
    "Let's start by setting up our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae03918",
   "metadata": {},
   "source": [
    "#### Problem parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b6b862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#Number of particles\n",
    "N = 2000\n",
    "#Start time\n",
    "tStart = 0\n",
    "#End time\n",
    "tEnd = 1.\n",
    "#Time step\n",
    "dt = 0.2\n",
    "#Number of steps\n",
    "tSteps = math.ceil((tEnd - tStart)/dt)\n",
    "#Newton's constant\n",
    "G = 1.0\n",
    "#Softening length to account for particles that are very close\n",
    "softening = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce44e9c2",
   "metadata": {},
   "source": [
    "#### Initializing particles (position, velocity,  mass) in the 3D-space\n",
    "We will initialize matrices of size N with the position (3D), velocity (3D), and mass (1D) of each particle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce912904",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17)\n",
    "\n",
    "#Position\n",
    "pos = np.random.randn(N, 3)\n",
    "#Velocity\n",
    "vel = np.random.randn(N, 3)\n",
    "#Mass\n",
    "mass = 20. * np.ones((N, 1)) / N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74fda8f",
   "metadata": {},
   "source": [
    "#### Helper functions\n",
    "We will create some helper functions here - we will optimize these later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "333eba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hadamard product\n",
    "# Input: Matrix x (M x N), Matrix y (M x N)\n",
    "# Output: Matrix (M x N)\n",
    "def hadMatMat(x, y):\n",
    "    return x * y\n",
    "\n",
    "# Scaling of matrix x\n",
    "# Input: Matrix x (M x N), scalar val\n",
    "# Output: Matrix (M x N)\n",
    "def sclMat(x, val):\n",
    "    return val * x\n",
    "\n",
    "# Matrix-Matrix product of matrices x,y\n",
    "# Input: Matrix x (M x K), Matrix y (K x N)\n",
    "# Output: Matrix (M x N)\n",
    "def mulMatMat(x, y):\n",
    "    return x @ y\n",
    "\n",
    "# Computation of 1/|r_i - r_j|^3\n",
    "# Input: Particle separations dx (N x N), dy (N x N), dz (N x N), softening (scalar)\n",
    "# Output: inv_r3 (N x N)\n",
    "def computeInvR3(dx, dy, dz, softening):\n",
    "    inv_r3 = (dx**2 + dy**2 + dz**2 + softening**2)\n",
    "    for i in range(inv_r3.shape[0]):\n",
    "        for j in range(inv_r3.shape[1]):\n",
    "            if (inv_r3[i,j] > 0):\n",
    "                inv_r3[i,j] = inv_r3[i,j]**(-1.5)\n",
    "    return inv_r3\n",
    "\n",
    "# Pairwise particle separations r_j - r_i per dimension\n",
    "# Input: Particle position in single dimension (N x 1)\n",
    "# Output: matrix of separations N x N\n",
    "def particleSeps(v):\n",
    "    return v.T - v\n",
    "\n",
    "# Computation of acceleration per dimension\n",
    "# Input: velocity (N x 1), inv_r3 (N x N), mass (N x 1), G (scalar)\n",
    "# Output: acceleration (N x 1)\n",
    "def computeAcc(dv, inv_r3, mass, G): \n",
    "    av = hadMatMat(dv, inv_r3)\n",
    "    av = sclMat(av, G)\n",
    "    av = mulMatMat(av, mass)\n",
    "    return av\n",
    "\n",
    "# Computation of acceleration \n",
    "# Input: positions (N x 3), mass (N x 1), G (scalar), softening (scalar)\n",
    "# Output: accelerations (N x 3)\n",
    "def getAcc(pos, mass, G, softening):\n",
    "    # Positions for all particles\n",
    "    x = pos[:, 0:1]\n",
    "    y = pos[:, 1:2]\n",
    "    z = pos[:, 2:3]\n",
    "    \n",
    "    # Particle separations\n",
    "    dx = particleSeps(x)\n",
    "    dy = particleSeps(y)\n",
    "    dz = particleSeps(z)\n",
    "    \n",
    "    # 1/r^3 for all particle separations\n",
    "    inv_r3 = computeInvR3(dx, dy, dz, softening)\n",
    "    \n",
    "    # Acceleration components per dimension\n",
    "    ax = computeAcc(dx, inv_r3, mass, G)\n",
    "    ay = computeAcc(dy, inv_r3, mass, G)\n",
    "    az = computeAcc(dz, inv_r3, mass, G)\n",
    "    \n",
    "    # Packing acceleration components\n",
    "    a = np.hstack((ax, ay, az))\n",
    "    \n",
    "    return a\n",
    "    \n",
    "# Computation of kinetic energy KE\n",
    "# Input: positions (N x 3), mass (N x 1), velocity (N x 3), G (scalar)\n",
    "# Output: KE (scalar)\n",
    "def getEnergy(mass, vel):\n",
    "    # Compute kinetic energy\n",
    "    KE = 0.5 * np.sum(mass * vel**2)\n",
    "    return KE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fd0d8e",
   "metadata": {},
   "source": [
    "#### Main n-body loop\n",
    "Let's put it all together in the main n-body loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56fbed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbody(mass, pos, vel, dt, tSteps, G, softening):\n",
    "    # Convert to center-of-mass frame\n",
    "    vel -= (np.sum(mass * vel) / (mass.shape[0] * vel.shape[1])) / (np.sum(mass) / (mass.shape[0] * mass.shape[1]))\n",
    "    \n",
    "    # Calculate initial gravitational accelerations\n",
    "    acc = getAcc(pos, mass, G, softening)\n",
    "    \n",
    "    # Calculate initial energy\n",
    "    KE = getEnergy(mass, vel)\n",
    "    \n",
    "    for i in range(tSteps):\n",
    "        # First kick (1/2) -- Compute velocity\n",
    "        vel += acc * dt / 2.0\n",
    "        \n",
    "        # Drift -- Update position\n",
    "        pos += vel * dt\n",
    "        \n",
    "        # Update acceleration\n",
    "        acc = getAcc(pos, mass, G, softening)\n",
    "        \n",
    "        # Second kick (1/2) -- Compute velocity\n",
    "        vel += acc * dt / 2.0\n",
    "\n",
    "        KE = getEnergy(mass, vel)\n",
    "        \n",
    "    return KE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e86656",
   "metadata": {},
   "source": [
    "#### Run n-body\n",
    "Now we can run our first N-body simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c08be4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kinetic Energy:  110.38075827435034\n"
     ]
    }
   ],
   "source": [
    "KE = nbody(mass, pos, vel, dt, tSteps, G, softening)\n",
    "print(\"Kinetic Energy: \", KE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5632bb8",
   "metadata": {},
   "source": [
    "## Exercise 1: Profile the N-body code\n",
    "\n",
    "We will now profile the N-body given above, using Python `cProfile` and `pstats`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0dbc156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         383 function calls in 8.345 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 49 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        6    7.738    1.290    7.738    1.290 /tmp/ipykernel_2412/917823000.py:22(computeInvR3)\n",
      "       18    0.213    0.012    0.213    0.012 /tmp/ipykernel_2412/917823000.py:33(particleSeps)\n",
      "       18    0.189    0.010    0.189    0.010 /tmp/ipykernel_2412/917823000.py:4(hadMatMat)\n",
      "       18    0.168    0.009    0.168    0.009 /tmp/ipykernel_2412/917823000.py:10(sclMat)\n",
      "       18    0.023    0.001    0.023    0.001 /tmp/ipykernel_2412/917823000.py:16(mulMatMat)\n",
      "       18    0.010    0.001    0.389    0.022 /tmp/ipykernel_2412/917823000.py:39(computeAcc)\n",
      "        1    0.003    0.003    8.344    8.344 /tmp/ipykernel_2412/3995771557.py:1(nbody)\n",
      "        2    0.001    0.000    0.001    0.000 {method 'randn' of 'numpy.random.mtrand.RandomState' objects}\n",
      "        6    0.000    0.000    0.000    0.000 /tmp/ipykernel_2412/917823000.py:75(getEnergy)\n",
      "        6    0.000    0.000    8.341    1.390 /tmp/ipykernel_2412/917823000.py:48(getAcc)\n",
      "\n",
      "\n",
      "Kinetic Energy:  110.38075827435034\n"
     ]
    }
   ],
   "source": [
    "import cProfile, pstats\n",
    "\n",
    "##TODO: Add a cProfile profiler \n",
    "profiler = cProfile.Profile()\n",
    "##TODO: Start the profiler\n",
    "profiler.enable()\n",
    "#Initializing particles position, mass, and velocity\n",
    "np.random.seed(17)\n",
    "#Position\n",
    "pos = np.random.randn(N, 3)\n",
    "#Velocity\n",
    "vel = np.random.randn(N, 3)\n",
    "#Mass\n",
    "mass = 20. * np.ones((N, 1)) / N\n",
    "\n",
    "KE = nbody(mass, pos, vel, dt, tSteps, G, softening)\n",
    "\n",
    "\n",
    "##TODO: Stop the profiler\n",
    "profiler.disable()\n",
    "##TODO: Print profiler statistics (top 10) based on the tottime\n",
    "stats = pstats.Stats(profiler).sort_stats('tottime')\n",
    "stats.print_stats(10)\n",
    "print(\"Kinetic Energy: \", KE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f816d4f1",
   "metadata": {},
   "source": [
    "### *Important note:* In iPython, we can use `IPython magic` to time the execution of a cell or a Python statement or expression. \n",
    "\n",
    "We can use `%%time` to measure the execution time of a cell, or `%%timeit`, to measure the execution time of a function in a cell (IPython will perform a number of repetitions and report the average).\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee7c1779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 12.5 s, total: 23.5 s\n",
      "Wall time: 8.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "KE = nbody(mass, pos, vel, dt, tSteps, G, softening)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eee24f",
   "metadata": {},
   "source": [
    "## Exercise 2: Accelerate the slowest functions using Numba\n",
    "\n",
    "The profile of N-body shows that many functions consume considerable amount of the total execution time and can therefore be optimized. We will now use Numba decorators, to see how much acceleration we can achieve through Numba compiler optimizations. Start with annotating the most time-consuming function. Then, proceed to annotate as many functions as needed with Numba decorators. Use the `nopython=True` mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0af7053",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##TODO: Use Numba to accelerate as many functions as possible\n",
    "import numba\n",
    "\n",
    "##TODO: Use Numba decorator if needed\n",
    "\n",
    "# Hadamard product\n",
    "# Input: Matrix x (M x N), Matrix y (M x N)\n",
    "# Output: Matrix (M x N)\n",
    "@numba.jit(nopython=True)\n",
    "def hadMatMat(x, y):\n",
    "    return x * y\n",
    "\n",
    "##TODO: Use Numba decorator if needed\n",
    "\n",
    "# Scaling of matrix x\n",
    "# Input: Matrix x (M x N), scalar val\n",
    "# Output: Matrix (M x N)\n",
    "@numba.jit(nopython=True)\n",
    "def sclMat(x, val):\n",
    "    return val * x\n",
    "\n",
    "##TODO: Use Numba decorator if needed\n",
    "\n",
    "# Matrix-Matrix product of matrices x,y\n",
    "# Input: Matrix x (M x K), Matrix y (K x N)\n",
    "# Output: Matrix (M x N)\n",
    "@numba.jit(nopython=True)\n",
    "def mulMatMat(x, y):\n",
    "    return x @ y\n",
    "\n",
    "##TODO: Use Numba decorator if needed\n",
    "\n",
    "# Computation of 1/|r_i - r_j|^3\n",
    "# Input: Particle separations dx (N x N), dy (N x N), dz (N x N), softening (scalar)\n",
    "# Output: inv_r3 (N x N)\n",
    "@numba.jit(nopython=True)\n",
    "def computeInvR3(dx, dy, dz, softening):\n",
    "    inv_r3 = (dx**2 + dy**2 + dz**2 + softening**2)\n",
    "    for i in range(inv_r3.shape[0]):\n",
    "        for j in range(inv_r3.shape[1]):\n",
    "            if (inv_r3[i,j] > 0):\n",
    "                inv_r3[i,j] = inv_r3[i,j]**(-1.5)\n",
    "    return inv_r3\n",
    "\n",
    "##TODO: Use Numba decorator if needed\n",
    "\n",
    "# Pairwise particle separations r_j - r_i per dimension\n",
    "# Input: Particle position in single dimension (1 x N)\n",
    "# Output: matrix of separations N x N\n",
    "@numba.jit(nopython=True)\n",
    "def particleSeps(v):\n",
    "    return v.T - v\n",
    "\n",
    "##TODO: Use Numba decorator if needed\n",
    "\n",
    "# Computation of acceleration per dimension\n",
    "# Input: velocity (N x 1), inv_r3 (N x N), mass (1 x N), G (scalar)\n",
    "# Output: acceleration (N x 1)\n",
    "@numba.jit(nopython=True)\n",
    "def computeAcc(dv, inv_r3, mass, G): \n",
    "    av = hadMatMat(dv, inv_r3)\n",
    "    av = sclMat(av, G)\n",
    "    av = mulMatMat(av, mass)\n",
    "    return av\n",
    "\n",
    "##TODO: Use Numba decorator if needed\n",
    "\n",
    "# Computation of acceleration \n",
    "# Input: positions (N x 3), mass (N x 1), G (scalar), softening (scalar)\n",
    "# Output: accelerations (N x 3)\n",
    "@numba.jit(nopython=True)\n",
    "def getAcc(pos, mass, G, softening):\n",
    "    # Positions for all particles\n",
    "    x = pos[:, 0:1]\n",
    "    y = pos[:, 1:2]\n",
    "    z = pos[:, 2:3]\n",
    "    \n",
    "    # Particle separations\n",
    "    dx = particleSeps(x)\n",
    "    dy = particleSeps(y)\n",
    "    dz = particleSeps(z)\n",
    "    \n",
    "    # 1/r^3 for all particle separations\n",
    "    inv_r3 = computeInvR3(dx, dy, dz, softening)\n",
    "    \n",
    "    # Acceleration components per dimension\n",
    "    ax = computeAcc(dx, inv_r3, mass, G)\n",
    "    ay = computeAcc(dy, inv_r3, mass, G)\n",
    "    az = computeAcc(dz, inv_r3, mass, G)\n",
    "    \n",
    "    # Packing acceleration components\n",
    "    a = np.hstack((ax, ay, az))\n",
    "    \n",
    "    return a\n",
    "    \n",
    "##TODO: Use Numba decorator if needed\n",
    "\n",
    "# Computation of kinetic energy KE\n",
    "# Input: positions (N x 3), mass (N x 1), velocity (N x 3), G (scalar)\n",
    "# Output: KE (scalar)\n",
    "@numba.jit(nopython=True)\n",
    "def getEnergy(mass, vel):\n",
    "    # Compute kinetic energy\n",
    "    KE = 0.5 * np.sum(mass * vel**2)\n",
    "    return KE\n",
    "\n",
    "##TODO: Use Numba decorator if needed\n",
    "\n",
    "# Computation of kinetic energy KE\n",
    "# Input: positions (N x 3), mass (N x 1), velocity (N x 3), G (scalar)\n",
    "# Output: KE (scalar)\n",
    "@numba.jit(nopython=True)\n",
    "def getEnergy(mass, vel):\n",
    "    # Compute kinetic energy\n",
    "    KE = 0.5 * np.sum(mass * vel**2)\n",
    "    return KE\n",
    "\n",
    "##TODO: Use Numba decorator if needed\n",
    "@numba.jit(nopython=True)\n",
    "def nbody(mass, pos, vel, dt, tSteps, G, softening):\n",
    "    # Convert to center-of-mass frame\n",
    "    vel -= (np.sum(mass * vel) / (mass.shape[0] * vel.shape[1])) / (np.sum(mass) / (mass.shape[0] * mass.shape[1]))\n",
    "    \n",
    "    # Calculate initial gravitational accelerations\n",
    "    acc = getAcc(pos, mass, G, softening)\n",
    "    \n",
    "    # Calculate initial energy\n",
    "    KE = getEnergy(mass, vel)\n",
    "    \n",
    "    for i in range(tSteps):\n",
    "        # First kick (1/2) -- Compute velocity\n",
    "        vel += acc * dt / 2.0\n",
    "        \n",
    "        # Drift -- Update position\n",
    "        pos += vel * dt\n",
    "        \n",
    "        # Update acceleration\n",
    "        acc = getAcc(pos, mass, G, softening)\n",
    "        \n",
    "        # Second kick (1/2) -- Compute velocity\n",
    "        vel += acc * dt / 2.0\n",
    "\n",
    "        KE = getEnergy(mass, vel)\n",
    "        \n",
    "    return KE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d621bf",
   "metadata": {},
   "source": [
    "Let's measure the execution time using Numba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe0dcc3a-6d3b-40cc-809a-2ad976d21a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize particles position, mass, and velocity\n",
    "np.random.seed(17)\n",
    "#Position\n",
    "pos = np.random.randn(N, 3)\n",
    "#Velocity\n",
    "vel = np.random.randn(N, 3)\n",
    "#Mass\n",
    "mass = 20. * np.ones((N, 1)) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddaa280a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.06 s ± 522 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "KE = nbody(mass, pos, vel, dt, tSteps, G, softening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6450e237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kinetic Energy:  59.76978330223841\n"
     ]
    }
   ],
   "source": [
    "print(\"Kinetic Energy: \", KE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341d722d",
   "metadata": {},
   "source": [
    "### *Important note:* If we try to use the Python profiler with Numba, we will not be able to get useful information about the most-time consuming functions anymore, as there are now dispatched to / handled by Numba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372a770a",
   "metadata": {},
   "source": [
    "## Exercise 3: Parallelize the `computeInvR3` function using Numba\n",
    "\n",
    "We will now parallelize a function using Numba. We will try to use both implicit and explicit parallelization. For the function `computeInvR3`, modify your Numba annotation, to include the `parallel=True` mode. This is implicit parallelization. Then you can try using `numba.prange` to mark the function loops as parallelizable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd8dc44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: Parallelize the computeInvR3 function using Numba\n",
    "\n",
    "##TODO: add a Numba decorator\n",
    "@numba.jit(nopython=True, parallel=True)\n",
    "def computeInvR3(dx, dy, dz, softening):\n",
    "    inv_r3 = (dx**2 + dy**2 + dz**2 + softening**2)\n",
    "    ##TODO: substitute range with numba.prange\n",
    "    for i in numba.prange(inv_r3.shape[0]):\n",
    "        for j in numba.prange(inv_r3.shape[1]):\n",
    "            if (inv_r3[i,j] > 0):\n",
    "                inv_r3[i,j] = inv_r3[i,j]**(-1.5)\n",
    "    return inv_r3\n",
    "\n",
    "#TODO: add a Numba decorator\n",
    "\n",
    "# Computation of acceleration \n",
    "# Input: positions (N x 3), mass (N x 1), G (scalar), softening (scalar)\n",
    "# Output: accelerations (N x 3)\n",
    "@numba.jit(nopython=True)\n",
    "def getAcc(pos, mass, G, softening):\n",
    "    # Positions for all particles\n",
    "    x = pos[:, 0:1]\n",
    "    y = pos[:, 1:2]\n",
    "    z = pos[:, 2:3]\n",
    "    \n",
    "    # Particle separations\n",
    "    dx = particleSeps(x)\n",
    "    dy = particleSeps(y)\n",
    "    dz = particleSeps(z)\n",
    "    \n",
    "    # 1/r^3 for all particle separations\n",
    "    inv_r3 = computeInvR3(dx, dy, dz, softening)\n",
    "    \n",
    "    # Acceleration components per dimension\n",
    "    ax = computeAcc(dx, inv_r3, mass, G)\n",
    "    ay = computeAcc(dy, inv_r3, mass, G)\n",
    "    az = computeAcc(dz, inv_r3, mass, G)\n",
    "    \n",
    "    # Packing acceleration components\n",
    "    a = np.hstack((ax, ay, az))\n",
    "    \n",
    "    return a\n",
    "\n",
    "\n",
    "#TODO: add a Numba decorator\n",
    "@numba.jit(nopython=True)\n",
    "def nbody(mass, pos, vel, dt, tSteps, G, softening):\n",
    "    # Convert to center-of-mass frame\n",
    "    vel -= (np.sum(mass * vel) / (mass.shape[0] * vel.shape[1])) / (np.sum(mass) / (mass.shape[0] * mass.shape[1]))\n",
    "    \n",
    "    # Calculate initial gravitational accelerations\n",
    "    acc = getAcc(pos, mass, G, softening)\n",
    "    \n",
    "    # Calculate initial energy\n",
    "    KE = getEnergy(mass, vel)\n",
    "    \n",
    "    for i in range(tSteps):\n",
    "        # First kick (1/2) -- Compute velocity\n",
    "        vel += acc * dt / 2.0\n",
    "        \n",
    "        # Drift -- Update position\n",
    "        pos += vel * dt\n",
    "        \n",
    "        # Update acceleration\n",
    "        acc = getAcc(pos, mass, G, softening)\n",
    "        \n",
    "        # Second kick (1/2) -- Compute velocity\n",
    "        vel += acc * dt / 2.0\n",
    "\n",
    "        KE = getEnergy(mass, vel)\n",
    "        \n",
    "    return KE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5adbd72",
   "metadata": {},
   "source": [
    "Before we run N-body, let's discover the number of threads on our CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c855753f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads:  16\n"
     ]
    }
   ],
   "source": [
    "print(\"Threads: \", numba.get_num_threads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90364a5d-6b35-49db-b940-a778c36ede9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize particles position, mass, and velocity\n",
    "np.random.seed(17)\n",
    "#Position\n",
    "pos = np.random.randn(N, 3)\n",
    "#Velocity\n",
    "vel = np.random.randn(N, 3)\n",
    "#Mass\n",
    "mass = 20. * np.ones((N, 1)) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26d1a62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.01 s ± 55.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "KE = nbody(mass, pos, vel, dt, tSteps, G, softening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc63109d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.76978330223841\n"
     ]
    }
   ],
   "source": [
    "print(KE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c9a06f",
   "metadata": {},
   "source": [
    "## Exercise 4: Accelerate the `computeInvR3` function on the GPU using Numba\n",
    "\n",
    "We will use the GPU to accelerate the `computeInvR3` function. Before we begin, we will first rewrite this function to make it more friendly to the CUDA programming style. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a81a5a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "def computeInvR3(dx, dy, dz, softening):\n",
    "    inv_r3 = np.empty((dx.shape[0], dx.shape[1]), dtype = np.float32)\n",
    "    for i in range(dx.shape[0]):\n",
    "        for j in range(dx.shape[1]):\n",
    "            inv_r3[i,j] = dx[i,j]**2 + dy[i,j]**2 + dz[i,j]**2 + softening**2\n",
    "            if (inv_r3[i,j] > 0):\n",
    "                inv_r3[i,j] = inv_r3[i,j]**(-1.5)\n",
    "    return inv_r3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f9e2fa",
   "metadata": {},
   "source": [
    "### Exercise 4.1:  Re-write the function `computeInvR3` with the correct arguments and annotate it with Numba\n",
    "Remember that CUDA Numba functions must not return any values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4156cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_HOME']='/chalmers/sw/sup64/cuda_toolkit-11.2.2'\n",
    "\n",
    "from numba import cuda\n",
    "\n",
    "##TODO: Annotate this function with Numba\n",
    "##TODO: Change the function arguments\n",
    "@numba.cuda.jit\n",
    "def computeInvR3(dx, dy, dz, softening, inv_r3):\n",
    "    ##TODO: Do we really need this initialization?    \n",
    "    # inv_r3 = np.empty((dx.shape[0], dx.shape[1]), dtype = np.float32)\n",
    "    for i in range(dx.shape[0]):\n",
    "        for j in range(dx.shape[1]):\n",
    "            inv_r3[i,j] = dx[i,j]**2 + dy[i,j]**2 + dz[i,j]**2 + softening**2\n",
    "            if (inv_r3[i,j] > 0):\n",
    "                inv_r3[i,j] = inv_r3[i,j]**(-1.5)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef672412",
   "metadata": {},
   "source": [
    "### Exercise 4.2:  Distribute the work in the function to threads and blocks of threads\n",
    "Since all the matrices used in the function are 2D (`dx`, `dy`, `dz` and `inv_r3`), we will assume a 2D grid of threads and 2D blocks of threads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "07d7b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: Copy the computeInvR3 function from the previous cell \n",
    "##TODO: ...and rewrite it to make it CUDA-friendly\n",
    "@cuda.jit(device=True)\n",
    "def my_pow(x, y):\n",
    "    return x ** y\n",
    "\n",
    "@numba.cuda.jit\n",
    "def computeInvR3(dx, dy, dz, softening, inv_r3):\n",
    "    i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "    j = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
    "    if (i >= dx.shape[0] or j >= dx.shape[1]):\n",
    "        return\n",
    "    inv_r3[i, j] = my_pow(dx[i, j], 2) + my_pow(dy[i, j], 2) + my_pow(dz[i, j], 2) + my_pow(softening[0], 2)\n",
    "    # inv_r3[i,j] = dx[i,j]**2 + dy[i,j]**2 + dz[i,j]**2 + softening**2\n",
    "    if (inv_r3[i,j] > 0):\n",
    "        inv_r3[i,j] = my_pow(inv_r3[i,j], (-1.5))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f9513a",
   "metadata": {},
   "source": [
    "### Exercise 4.3: Copy the input matrices from the CPU to the GPU and the results from the GPU to the CPU\n",
    "Remember that, when the function is called, data is initially allocated on the CPU. To run the function on the GPU, we need to transfer all data (`dx`, `dy`, `dz`) to the GPU. Once the function is complete, we also need to copy the result `inv_r3` from the GPU to the CPU.\n",
    "\n",
    "### Exercise 4.4: Allocate space on the GPU for the result of the function\n",
    "The result of the operation `inv_r3` is produced on the GPU. Before we call the function, we need to allocate space for this matrix on the GPU. \n",
    "\n",
    "### Exercise 4.5: Launch the kernel\n",
    "Before we launch the kernel, we need to define the number of threads per block (total maximum = 1024 for this GPU) and the number of blocks in the grid. We can then launch the kernel by calling the GPU-accelerated function. We assume that the thread blocks will be 2-dimensional and of size (32,32). Define the number of blocks in the grid and launch the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "770dd3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Computation of acceleration \n",
    "# Input: positions (N x 3), mass (N x 1), G (scalar), softening (scalar)\n",
    "# Output: accelerations (N x 3)\n",
    "def getAcc(pos, mass, G, softening):\n",
    "    # Positions for all particles\n",
    "    x = pos[:, 0:1]\n",
    "    y = pos[:, 1:2]\n",
    "    z = pos[:, 2:3]\n",
    "    \n",
    "    # Particle separations\n",
    "    dx = particleSeps(x)\n",
    "    dy = particleSeps(y)\n",
    "    dz = particleSeps(z)\n",
    "    \n",
    "    ##TODO: Copy dx, dy, dz to the GPU\n",
    "    ##TODO: Uncomment and fill in the next three lines\n",
    "    gpu_dx = cuda.to_device(dx)\n",
    "    gpu_dy = cuda.to_device(dy)\n",
    "    gpu_dz = cuda.to_device(dz)\n",
    "    gpu_softening = cuda.to_device([softening])\n",
    "    \n",
    "    ##TODO: Allocate space for inv_r3 on the GPU \n",
    "    ##TODO: Uncomment and fill in the next line\n",
    "    # inv_r3 = np.empty((dx.shape[0], dx.shape[1]), dtype = np.float32)\n",
    "    inv_r3_gpu = cuda.device_array_like(dx)\n",
    "    \n",
    "    threadsperblock = (32,32)\n",
    "    #TODO: Define the number of blocks in the grid\n",
    "    ##TODO: Define the number of blocks in the grid\n",
    "    ##TODO: Uncomment and fill in the next line\n",
    "    blockspergrid = (math.ceil(x.shape[0] / threadsperblock[0]),\n",
    "                     math.ceil(x.shape[1] / threadsperblock[1])\n",
    "                    )\n",
    "    \n",
    "    ##TODO: Launch the kernel `computeInvR3`\n",
    "    ##TODO: Uncomment and fill in the next line\n",
    "    #computeInvR3\n",
    "    computeInvR3[blockspergrid, threadsperblock](gpu_dx, gpu_dy, gpu_dz, gpu_softening, inv_r3_gpu)\n",
    "    ##TODO: Copy inv_r3 back to the CPU\n",
    "    ##TODO: Uncomment and fill in the next line\n",
    "    inv_r3 = inv_r3_gpu.copy_to_host()\n",
    "    \n",
    "    # Acceleration components per dimension\n",
    "    ax = computeAcc(dx, inv_r3, mass, G)\n",
    "    ay = computeAcc(dy, inv_r3, mass, G)\n",
    "    az = computeAcc(dz, inv_r3, mass, G)\n",
    "    \n",
    "    # Packing acceleration components\n",
    "    a = np.hstack((ax, ay, az))\n",
    "    \n",
    "    return a\n",
    "\n",
    "def nbody(mass, pos, vel, dt, tSteps, G, softening):\n",
    "    # Convert to center-of-mass frame\n",
    "    vel -= (np.sum(mass * vel) / (mass.shape[0] * vel.shape[1])) / (np.sum(mass) / (mass.shape[0] * mass.shape[1]))\n",
    "    \n",
    "    # Calculate initial gravitational accelerations\n",
    "    acc = getAcc(pos, mass, G, softening)\n",
    "    \n",
    "    # Calculate initial energy\n",
    "    KE = getEnergy(mass, vel)\n",
    "    \n",
    "    for i in range(tSteps):\n",
    "        # First kick (1/2) -- Compute velocity\n",
    "        vel += acc * dt / 2.0\n",
    "        \n",
    "        # Drift -- Update position\n",
    "        pos += vel * dt\n",
    "        \n",
    "        # Update acceleration\n",
    "        acc = getAcc(pos, mass, G, softening)\n",
    "        \n",
    "        # Second kick (1/2) -- Compute velocity\n",
    "        vel += acc * dt / 2.0\n",
    "\n",
    "        KE = getEnergy(mass, vel)\n",
    "        \n",
    "    return KE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4181be10-daa1-41c8-8d77-cea8540689cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.1)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cupy\n",
    "cupy.ones((2,2)).device\n",
    "a = np.array(0.1)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf009d",
   "metadata": {},
   "source": [
    "We are all set! Before we run nbody, let's discover our GPUs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "abd2e769-af28-45dd-b3d7-4891b5f2f64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA-enabled GPUs: <Managed Device 0>\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA-enabled GPUs:\", cuda.gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6141fd3c-b01b-4813-babf-1350061b5a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize particles position, mass, and velocity\n",
    "np.random.seed(17)\n",
    "#Position\n",
    "pos = np.random.randn(N, 3)\n",
    "#Velocity\n",
    "vel = np.random.randn(N, 3)\n",
    "#Mass\n",
    "mass = 20. * np.ones((N, 1)) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e31d17ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790 ms ± 109 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "KE = nbody(mass, pos, vel, dt, tSteps, G, softening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "63d200e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.789274199762946\n"
     ]
    }
   ],
   "source": [
    "print(KE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5908f0",
   "metadata": {},
   "source": [
    "## Exercise 5: Accelerate N-body on the GPU using CuPy\n",
    "\n",
    "To accelerate the N-body kernel with CuPy, we will start with re-writing the application to use NumPy functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066beeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hadamard product\n",
    "# Input: Matrix x (M x N), Matrix y (M x N)\n",
    "# Output: Matrix (M x N)\n",
    "def hadMatMat(x, y):\n",
    "    return np.multiply(x,y)\n",
    "\n",
    "# Scaling of matrix x\n",
    "# Input: Matrix x (M x N), scalar val\n",
    "# Output: Matrix (M x N)\n",
    "def sclMat(x, val):\n",
    "    return np.multiply(x,val)\n",
    "\n",
    "# Matrix-Matrix product of matrices x,y\n",
    "# Input: Matrix x (M x K), Matrix y (K x N)\n",
    "# Output: Matrix (M x N)\n",
    "def mulMatMat(x, y):\n",
    "    return np.matmul(x,y)\n",
    "\n",
    "# Computation of 1/|r_i - r_j|^3\n",
    "# Input: Particle separations dx (N x N), dy (N x N), dz (N x N), softening (scalar)\n",
    "# Output: inv_r3 (N x N)\n",
    "def computeInvR3(dx, dy, dz, softening):\n",
    "    inv_r3 = np.add(np.add(np.add(dx**2, dy**2),dz**2),softening**2)\n",
    "    inv_r3[inv_r3>0] = inv_r3[inv_r3 > 0]**(-1.5) \n",
    "    return inv_r3\n",
    "\n",
    "# Pairwise particle separations r_j - r_i per dimension\n",
    "# Input: Particle position in single dimension (N x 1)\n",
    "# Output: matrix of separations N x N\n",
    "def particleSeps(v):\n",
    "    return np.subtract(np.transpose(v),v)\n",
    "\n",
    "# Computation of acceleration per dimension\n",
    "# Input: velocity (N x 1), inv_r3 (N x N), mass (N x 1), G (scalar)\n",
    "# Output: acceleration (N x 1)\n",
    "def computeAcc(dv, inv_r3, mass, G): \n",
    "    av = hadMatMat(dv, inv_r3)\n",
    "    av = sclMat(av, G)\n",
    "    av = mulMatMat(av, mass)\n",
    "    return av\n",
    "\n",
    "# Computation of acceleration \n",
    "# Input: positions (N x 3), mass (N x 1), G (scalar), softening (scalar)\n",
    "# Output: accelerations (N x 3)\n",
    "def getAcc(pos, mass, G, softening):\n",
    "    # Positions for all particles\n",
    "    x = pos[:, 0:1]\n",
    "    y = pos[:, 1:2]\n",
    "    z = pos[:, 2:3]\n",
    "    \n",
    "    # Particle separations\n",
    "    dx = particleSeps(x)\n",
    "    dy = particleSeps(y)\n",
    "    dz = particleSeps(z)\n",
    "    \n",
    "    # 1/r^3 for all particle separations\n",
    "    inv_r3 = computeInvR3(dx, dy, dz, softening)\n",
    "    \n",
    "    # Acceleration components per dimension\n",
    "    ax = computeAcc(dx, inv_r3, mass, G)\n",
    "    ay = computeAcc(dy, inv_r3, mass, G)\n",
    "    az = computeAcc(dz, inv_r3, mass, G)\n",
    "    \n",
    "    # Packing acceleration components\n",
    "    a = np.hstack((ax, ay, az))\n",
    "    \n",
    "    return a\n",
    "    \n",
    "# Computation of kinetic energy KE\n",
    "# Input: positions (N x 3), mass (N x 1), velocity (N x 3), G (scalar)\n",
    "# Output: KE (scalar)\n",
    "def getEnergy(mass, vel):\n",
    "    # Compute kinetic energy\n",
    "    KE = 0.5 * np.sum(mass * vel**2)\n",
    "    return KE\n",
    "\n",
    "def nbody(mass, pos, vel, dt, tSteps, G, softening):\n",
    "    # Convert to center-of-mass frame\n",
    "    vel -= (np.sum(mass * vel) / (mass.shape[0] * vel.shape[1])) / (np.sum(mass) / (mass.shape[0] * mass.shape[1]))\n",
    "    \n",
    "    # Calculate initial gravitational accelerations\n",
    "    acc = getAcc(pos, mass, G, softening)\n",
    "    \n",
    "    # Calculate initial energy\n",
    "    KE = getEnergy(mass, vel)\n",
    "    \n",
    "    for i in range(tSteps):\n",
    "        # First kick (1/2) -- Compute velocity\n",
    "        vel += acc * dt / 2.0\n",
    "        \n",
    "        # Drift -- Update position\n",
    "        pos += vel * dt\n",
    "        \n",
    "        # Update acceleration\n",
    "        acc = getAcc(pos, mass, G, softening)\n",
    "        \n",
    "        # Second kick (1/2) -- Compute velocity\n",
    "        vel += acc * dt / 2.0\n",
    "\n",
    "        KE = getEnergy(mass, vel)\n",
    "        \n",
    "    return KE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d0b4d8",
   "metadata": {},
   "source": [
    "We can now run the code again and see how using Numpy compares to using Numba. You can also use `cProfile` to analyze the execution time breakdown per function, as in Exercise #1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec01bcf7-5c73-4f55-ba48-aa6954a244f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize particles position, mass, and velocity\n",
    "\n",
    "np.random.seed(17)\n",
    "\n",
    "#Position\n",
    "pos = np.random.randn(N, 3)\n",
    "#Velocity\n",
    "vel = np.random.randn(N, 3)\n",
    "#Mass\n",
    "mass = 20. * np.ones((N, 1)) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "KE = nbody(mass, pos, vel, dt, tSteps, G, softening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ce3bd-3b7b-402b-91dc-69dc9ad6c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(KE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c88cc91",
   "metadata": {},
   "source": [
    "Let's now replace `numpy` with `cupy` and run all functions on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1ac3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Import cupy\n",
    "\n",
    "\n",
    "# Hadamard product\n",
    "# Input: Matrix x (M x N), Matrix y (M x N)\n",
    "# Output: Matrix (M x N)\n",
    "def hadMatMat(x, y):\n",
    "    return np.multiply(x,y)\n",
    "\n",
    "# Scaling of matrix x\n",
    "# Input: Matrix x (M x N), scalar val\n",
    "# Output: Matrix (M x N)\n",
    "def sclMat(x, val):\n",
    "    return np.multiply(x,val)\n",
    "\n",
    "# Matrix-Matrix product of matrices x,y\n",
    "# Input: Matrix x (M x K), Matrix y (K x N)\n",
    "# Output: Matrix (M x N)\n",
    "def mulMatMat(x, y):\n",
    "    return np.matmul(x,y)\n",
    "\n",
    "# Computation of 1/|r_i - r_j|^3\n",
    "# Input: Particle separations dx (N x N), dy (N x N), dz (N x N), softening (scalar)\n",
    "# Output: inv_r3 (N x N)\n",
    "def computeInvR3(dx, dy, dz, softening):\n",
    "    inv_r3 = np.add(np.add(np.add(dx**2, dy**2),dz**2),softening**2)\n",
    "    inv_r3[inv_r3>0] = inv_r3[inv_r3 > 0]**(-1.5) \n",
    "    return inv_r3\n",
    "\n",
    "# Pairwise particle separations r_j - r_i per dimension\n",
    "# Input: Particle position in single dimension (N x 1)\n",
    "# Output: matrix of separations N x N\n",
    "def particleSeps(v):\n",
    "    return np.subtract(np.transpose(v),v)\n",
    "\n",
    "# Computation of acceleration per dimension\n",
    "# Input: velocity (N x 1), inv_r3 (N x N), mass (N x 1), G (scalar)\n",
    "# Output: acceleration (N x 1)\n",
    "def computeAcc(dv, inv_r3, mass, G): \n",
    "    av = hadMatMat(dv, inv_r3)\n",
    "    av = sclMat(av, G)\n",
    "    av = mulMatMat(av, mass)\n",
    "    return av\n",
    "\n",
    "# Computation of acceleration \n",
    "# Input: positions (N x 3), mass (N x 1), G (scalar), softening (scalar)\n",
    "# Output: accelerations (N x 3)\n",
    "def getAcc(pos, mass, G, softening):\n",
    "    # Positions for all particles\n",
    "    x = pos[:, 0:1]\n",
    "    y = pos[:, 1:2]\n",
    "    z = pos[:, 2:3]\n",
    "    \n",
    "    # Particle separations\n",
    "    dx = particleSeps(x)\n",
    "    dy = particleSeps(y)\n",
    "    dz = particleSeps(z)\n",
    "    \n",
    "    # 1/r^3 for all particle separations\n",
    "    inv_r3 = computeInvR3(dx, dy, dz, softening)\n",
    "    \n",
    "    # Acceleration components per dimension\n",
    "    ax = computeAcc(dx, inv_r3, mass, G)\n",
    "    ay = computeAcc(dy, inv_r3, mass, G)\n",
    "    az = computeAcc(dz, inv_r3, mass, G)\n",
    "    \n",
    "    # Packing acceleration components\n",
    "    a = np.hstack((ax, ay, az))\n",
    "    \n",
    "    return a\n",
    "    \n",
    "# Computation of kinetic energy KE\n",
    "# Input: positions (N x 3), mass (N x 1), velocity (N x 3), G (scalar)\n",
    "# Output: KE (scalar)\n",
    "def getEnergy(mass, vel):\n",
    "    # Compute kinetic energy\n",
    "    KE = 0.5 * np.sum(mass * vel**2)\n",
    "    return KE\n",
    "\n",
    "def nbody(mass, pos, vel, dt, tSteps, G, softening):\n",
    "    # Convert to center-of-mass frame\n",
    "    vel -= (np.sum(mass * vel) / (mass.shape[0] * vel.shape[1])) / (np.sum(mass) / (mass.shape[0] * mass.shape[1]))\n",
    "    \n",
    "    # Calculate initial gravitational accelerations\n",
    "    acc = getAcc(pos, mass, G, softening)\n",
    "    \n",
    "    # Calculate initial energy\n",
    "    KE = getEnergy(mass, vel)\n",
    "    \n",
    "    for i in range(tSteps):\n",
    "        # First kick (1/2) -- Compute velocity\n",
    "        vel += acc * dt / 2.0\n",
    "        \n",
    "        # Drift -- Update position\n",
    "        pos += vel * dt\n",
    "        \n",
    "        # Update acceleration\n",
    "        acc = getAcc(pos, mass, G, softening)\n",
    "        \n",
    "        # Second kick (1/2) -- Compute velocity\n",
    "        vel += acc * dt / 2.0\n",
    "\n",
    "        KE = getEnergy(mass, vel)\n",
    "        \n",
    "    return KE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d97c8a",
   "metadata": {},
   "source": [
    "We will need to re-initialize our arrays with `cupy`, not just for correctness, but also to allocate them on the GPU instead of the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de19823",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17)\n",
    "\n",
    "#Position\n",
    "pos = np.random.randn(N, 3)\n",
    "#Velocity\n",
    "vel = np.random.randn(N, 3)\n",
    "#Mass\n",
    "mass = 20. * np.ones((N, 1)) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943cac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "KE = nbody(mass, pos, vel, dt, tSteps, G, softening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6c76b5-f9bc-42e9-99c2-22a03ca210c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(KE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c838a",
   "metadata": {},
   "source": [
    "## Exercise 6: Profile N-body on the GPU using CuPy\n",
    "\n",
    "Having run our GPU-accelerated N-Body code, we can profile it using CuPy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49261a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: Import the `benchmark` function from CuPy\n",
    "\n",
    "##TODO: Use the benchmark function to profile nbody for 10 repetitions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bbdd87",
   "metadata": {},
   "source": [
    "## Exercise 7: Parallelize N-body for multiple processes using MPI (`mpi4py`)\n",
    "\n",
    "So far, we have been running on a single node (single CPU with multiple cores, and single GPU). However, if we want to scale our application out to multiple nodes, we need to parallelize the application with the appropriate programming model. We will be looking at parallelization across distributed nodes (i.e. a cluster with multiple interconnected nodes), and we will use MPI.\n",
    "\n",
    "For this exercise, we will distribute the *N* particles of the simulation to *P* processes, which will work together to compute the total kinetic energy *KE* of the system at each time step. \n",
    "\n",
    "As a reminder, we initialize three variables per particle, its mass *m*, its position *pos* and its velocity *v*. \n",
    "\n",
    "Below there is a template of the parallel function for N-body `parallel_nbody`, run with MPI with 4 processes. It currently only collects the size of the communicator (number of processes) and the rank (ID) of each process. You can run it and notice how *each* process executes the same piece of code, i.e. the `parallel_nbody` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd9817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "from mpi4py import MPI\n",
    "\n",
    "def parallel_nbody():\n",
    "    comm = MPI.COMM_WORLD\n",
    "    size = comm.Get_size()\n",
    "    rank = comm.Get_rank()\n",
    "    return f\"Size: {size} Rank: {rank}\"\n",
    "    \n",
    "with ipp.Cluster(engines='mpi', n = 4) as rc:\n",
    "    view = rc.broadcast_view()\n",
    "    r = view.apply_sync(parallel_nbody)\n",
    "    print(\"\\n\".join(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0cfc49",
   "metadata": {},
   "source": [
    "### Exercise 7.1: Distribute particles to processes with MPI\n",
    "\n",
    "The first step towards parallelization will be to distribute the particles, and in particular, their associated variables for mass, position, and velocity to all processes. For this purpose, the process with *rank = 0* will initialize the relevant arrays and will then distribute them to all processes. Your task is to determine the appropriate function, to distribute the particles. We will modify the `parallel_nbody` function accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda72985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "from mpi4py import MPI\n",
    "\n",
    "def parallel_nbody():\n",
    "    import numpy as np\n",
    "    import math\n",
    "\n",
    "    comm = MPI.COMM_WORLD\n",
    "    size = comm.Get_size()\n",
    "    rank = comm.Get_rank()\n",
    "    #Number of particles\n",
    "    N = 2000\n",
    "    #Other parameters\n",
    "    tStart = 0\n",
    "    tEnd = 1.\n",
    "    dt = 0.2\n",
    "    tSteps = math.ceil((tEnd - tStart)/dt)\n",
    "    G = 1.0\n",
    "    softening = 0.1\n",
    "\n",
    "    pos = None\n",
    "    vel = None\n",
    "    mass = None\n",
    "    if (rank == 0):\n",
    "        #IMPORTANT: We initialize all arrays as 1D, and then reshape\n",
    "        #IMPORTANT: This is to make sure that memory is contiguous\n",
    "        np.random.seed(17)\n",
    "        #Position\n",
    "        pos = np.random.randn(N * 3)\n",
    "        #Velocity\n",
    "        vel = np.random.randn(N * 3)\n",
    "        #Mass\n",
    "        mass = (20./ N) * np.ones(N) \n",
    "\n",
    "\n",
    "    #All processes initialize empty arrays of N / size particles\n",
    "    #IMPORTANT: MPI needs to send/receive from flattened arrays (2D->1D)\n",
    "    #IMPORTANT: We will initialize the arrays as 1D arrays and will reshape later\n",
    "    pos_local = np.zeros((math.ceil(N/size) * 3), dtype = np.float64)\n",
    "    vel_local = np.zeros((math.ceil(N/size) * 3), dtype = np.float64)\n",
    "    mass_local = np.zeros((math.ceil(N/size) * 1), dtype = np.float64)\n",
    "        \n",
    "    \n",
    "    #TODO: Replace comm.Dummy with the correct MPI function to distribute chunks of pos, vel, mass to all processes \n",
    "    #TODO: Use new arrays pos_local, vel_local, mass_local\n",
    "    comm.Dummy(pos, pos_local, root=0)\n",
    "    comm.Dummy(vel, vel_local, root=0)\n",
    "    comm.Dummy(mass, mass_local, root=0)\n",
    "    \n",
    "    if (rank == 0):\n",
    "        pos = pos.reshape(N, 3)\n",
    "        vel = vel.reshape(N, 3)\n",
    "        mass = mass.reshape(N, 1)\n",
    "\n",
    "    pos_local = pos_local.reshape(math.ceil(N/size),3)\n",
    "    vel_local = vel_local.reshape(math.ceil(N/size),3)\n",
    "    mass_local = mass_local.reshape(math.ceil(N/size),1)\n",
    "    \n",
    "    return \n",
    "    \n",
    "with ipp.Cluster(engines='MPI', n = 4) as rc:\n",
    "    view = rc.broadcast_view()\n",
    "    r = view.apply_sync(parallel_nbody)\n",
    "    print(\"\\n\".join(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc1d44f",
   "metadata": {},
   "source": [
    "### Exercise 7.2: Understand parallelism in the `nbody` function and use the appropriate MPI functions\n",
    "\n",
    "If we call `nbody` from the `parallel_nbody` function, all processes will run the N-body code on the particles they own. However, there are two places within the application where processes need to collaborate.  \n",
    "1. In the `getAcc` function, where we calculate the acceleration, we first need to calculate all the particle separations, i.e. all the interactions between all particles in the simulation. This calculation depends on positions `pos`. Therefore, before each process calls this function, we need to ensure that all processes get the updated positions of all particles from all other processes. Which function is required? \n",
    "2. In the `getAcc` function, the calculation of the acceleration depends on the masses of all particles in the simulation. Therefore, according to our proposed parallelization scheme, its process computes a partial acceleration for all particles, and needs to accumulate all the accelerations for all particles, in order to collect the acceleration for its own particles. This part is given, and also affects the `computeAcc` function. Which function is used?\n",
    "2. In the `nbody` function, each process calculates the kinetic energy KE of the particles that are assigned to it. However, eventually, we want to accumulate the kinetic energy from all processes and end up with all processes having the summed, global value for the whole system kinetic energy. Which function is required? \n",
    "\n",
    "Below, we will modify the two functions accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30467c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def parallel_nbody():\n",
    "    import numpy as np\n",
    "    import math\n",
    "\n",
    "    \n",
    "    def hadMatMat(x, y):\n",
    "        return np.multiply(x,y)\n",
    "\n",
    "\n",
    "    def sclMat(x, val):\n",
    "        return np.multiply(x,val)\n",
    "\n",
    "    def mulMatMat(x, y):\n",
    "        return np.matmul(x,y)\n",
    "\n",
    "    def computeInvR3(dx, dy, dz, softening):\n",
    "        inv_r3 = np.add(np.add(np.add(dx**2, dy**2),dz**2),softening**2)\n",
    "        inv_r3[inv_r3>0] = inv_r3[inv_r3 > 0]**(-1.5) \n",
    "        return inv_r3\n",
    "\n",
    "    def particleSeps(v):\n",
    "        return np.subtract(np.transpose(v),v)\n",
    "\n",
    "    def computeAcc(dv, inv_r3, local_mass, G, comm): \n",
    "        rank = comm.Get_rank()\n",
    "        size = comm.Get_size()\n",
    "        N = dv.shape[0]\n",
    "        av = hadMatMat(dv, inv_r3)\n",
    "        av = sclMat(av, G)\n",
    "        av = mulMatMat(av[:,rank * int(N/size):(rank+1) * int(N/size)], local_mass)\n",
    "        return av\n",
    "\n",
    "    def getAcc(local_pos, local_mass, G, softening, comm):\n",
    "        rank = comm.Get_rank()\n",
    "        size = comm.Get_size()\n",
    "        N = local_pos.shape[0] * size\n",
    "\n",
    "        # Positions for all particles\n",
    "\n",
    "        #This function gets local_pos as an argument, but pos is missing (all positions)\n",
    "        #Collect all `local_pos` from all other processes in one array, `pos`\n",
    "        \n",
    "        #IMPORTANT: We need to create flat arrays (1D) \n",
    "        pos = np.zeros(N * 3).reshape(N, 3)\n",
    "        #TODO: Replace comm.Dummy with the correct function\n",
    "        comm.Dummy(local_pos, pos)\n",
    "        \n",
    "        x = pos[:, 0:1]\n",
    "        y = pos[:, 1:2]\n",
    "        z = pos[:, 2:3]\n",
    "    \n",
    "        # Particle separations\n",
    "        dx = particleSeps(x)\n",
    "        dy = particleSeps(y)\n",
    "        dz = particleSeps(z)\n",
    "    \n",
    "        # 1/r^3 for all particle separations\n",
    "        inv_r3 = computeInvR3(dx, dy, dz, softening)\n",
    "    \n",
    "        # Acceleration components per dimension\n",
    "        partial_ax = computeAcc(dx, inv_r3, local_mass, G, comm)\n",
    "        partial_ay = computeAcc(dy, inv_r3, local_mass, G, comm)\n",
    "        partial_az = computeAcc(dz, inv_r3, local_mass, G, comm)\n",
    "        \n",
    "        ax = np.zeros(partial_ax.shape)\n",
    "        ay = np.zeros(partial_ay.shape)\n",
    "        az = np.zeros(partial_az.shape)\n",
    "        \n",
    "        comm.Allreduce(partial_ax, ax)\n",
    "        comm.Allreduce(partial_ay, ay)\n",
    "        comm.Allreduce(partial_az, ay)\n",
    "        # Packing acceleration components\n",
    "        a = np.hstack((ax[rank * int(N/size):(rank+1) * int(N/size), :], ay[rank * int(N/size):(rank+1) * int(N/size),:], az[rank * int(N/size):(rank+1) * int(N/size)]))\n",
    "        return a\n",
    "    \n",
    "    def getEnergy(local_mass, local_vel):\n",
    "        # Compute kinetic energy\n",
    "        KE = 0.5 * np.sum(local_mass * local_vel**2)\n",
    "        return KE\n",
    "\n",
    "    def nbody(local_mass, local_pos, local_vel, dt, tSteps, G, softening, comm):\n",
    "        # Convert to center-of-mass frame\n",
    "        local_vel -= (np.sum(local_mass * local_vel) / (local_mass.shape[0] * local_vel.shape[1])) / (np.sum(local_mass) / (local_mass.shape[0] * local_mass.shape[1]))\n",
    "        \n",
    "        # Calculate initial gravitational accelerations\n",
    "        local_acc = getAcc(local_pos, local_mass, G, softening, comm)\n",
    "        print(local_acc.shape)\n",
    "        # Calculate initial energy\n",
    "        local_KE = getEnergy(local_mass, local_vel)\n",
    "        \n",
    "        for i in range(tSteps):\n",
    "            # First kick (1/2) -- Compute velocity\n",
    "            \n",
    "            local_vel += local_acc * dt / 2.0\n",
    "            \n",
    "            # Drift -- Update position\n",
    "            local_pos += local_vel * dt\n",
    "        \n",
    "            # Update acceleration\n",
    "            local_acc = getAcc(local_pos, local_mass, G, softening, comm)\n",
    "        \n",
    "            # Second kick (1/2) -- Compute velocity\n",
    "            local_vel += local_acc * dt / 2.0\n",
    "\n",
    "            local_KE = getEnergy(local_mass, local_vel)\n",
    "            \n",
    "        #Return the \"global KE\": sum the local kinetic energies on all processes\n",
    "        KE = np.zeros(1)\n",
    "        #TODO: Replace comm.Dummy with the correct function\n",
    "        comm.Dummy(sendbuf=[local_KE, MPI.DOUBLE], recvbuf=[KE, MPI.DOUBLE])\n",
    "        return KE\n",
    "\n",
    "    comm = MPI.COMM_WORLD\n",
    "    size = comm.Get_size()\n",
    "    rank = comm.Get_rank()\n",
    "    #Number of particles\n",
    "    N = 2000\n",
    "    #Other parameters\n",
    "    tStart = 0\n",
    "    tEnd = 1.\n",
    "    dt = 0.2\n",
    "    tSteps = math.ceil((tEnd - tStart)/dt)\n",
    "    G = 1.0\n",
    "    softening = 0.1\n",
    "\n",
    "    pos = None\n",
    "    vel = None\n",
    "    mass = None\n",
    "    if (rank == 0):\n",
    "        np.random.seed(17)\n",
    "        #Position\n",
    "        pos = np.random.randn(N * 3)\n",
    "        #Velocity\n",
    "        vel = np.random.randn(N * 3)\n",
    "        #Mass\n",
    "        mass = (20./ N) * np.ones(N) \n",
    "\n",
    "\n",
    "    #All processes initialize empty arrays of N / size particles\n",
    "    #IMPORTANT: MPI needs to send/receive from flattened arrays (2D->1D)\n",
    "    #IMPORTANT: We will initialize the arrays as 1D arrays and will reshape later\n",
    "    pos_local = np.zeros((math.ceil(N/size) * 3), dtype = np.float64)\n",
    "    vel_local = np.zeros((math.ceil(N/size) * 3), dtype = np.float64)\n",
    "    mass_local = np.zeros((math.ceil(N/size) * 1), dtype = np.float64)\n",
    "        \n",
    "    \n",
    "    #TODO: Replace comm.Dummy with the correct MPI function to distribute chunks of pos, vel, mass to all processes \n",
    "    comm.Dummy(pos, pos_local, root=0)\n",
    "    comm.Dummy(vel, vel_local, root=0)\n",
    "    comm.Dummy(mass, mass_local, root=0)\n",
    "    \n",
    "    if (rank == 0):\n",
    "        pos = pos.reshape(N, 3)\n",
    "        vel = vel.reshape(N, 3)\n",
    "        mass = mass.reshape(N, 1)\n",
    "\n",
    "    pos_local = pos_local.reshape(math.ceil(N/size),3)\n",
    "    vel_local = vel_local.reshape(math.ceil(N/size),3)\n",
    "    mass_local = mass_local.reshape(math.ceil(N/size),1)\n",
    "    \n",
    "    #We can call the updated nbody function here\n",
    "    KE = nbody(mass_local, pos_local, vel_local, dt, tSteps, G, softening, comm)\n",
    "    return f'Rank {rank}, Energy {KE}'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30e3112",
   "metadata": {},
   "source": [
    "Now let's put it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d24b4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ipp.Cluster(engines='MPI', n = 4) as rc:\n",
    "    view = rc.broadcast_view()\n",
    "    r = view.apply(parallel_nbody)\n",
    "    print(\"\\n\".join(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15883c7c-4a82-4d8c-8f3f-16c11f4ecb88",
   "metadata": {},
   "source": [
    "# That's all, folks! #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
